--- mellanox/mlx4/en_cq.c	2012-09-11 20:50:55.982624673 -0700
+++ ./mellanox/mlx4/en_cq.c	2012-09-25 14:55:39.995504201 -0700
@@ -37,6 +37,10 @@
 
 #include "mlx4_en.h"
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#include <mlx4_netmap_linux.h>        /* extern stuff */
+#endif /* CONFIG_NETMAP */
+
 static void mlx4_en_cq_event(struct mlx4_cq *cq, enum mlx4_event event)
 {
 	return;
@@ -127,6 +131,15 @@ int mlx4_en_activate_cq(struct mlx4_en_p
 	cq->mcq.event = mlx4_en_cq_event;
 
 	if (cq->is_tx) {
+#if 0 // XXX def DEV_NETMAP
+		struct netmap_adapter *na = NA(priv->dev);
+		if (na && (priv->dev->if_capenable & IFCAP_NETMAP) && cq_idx < na->num_tx_rings) {
+			RD(5, "activate napi on txq %d ring %d", cq_idx, cq->ring);
+			netif_napi_add(cq->dev, &cq->napi, mlx4_en_poll_tx_cq, 64);
+			napi_enable(&cq->napi);
+			return 0;
+		}
+#endif /* !DEV_NETMAP */
 		init_timer(&cq->timer);
 		cq->timer.function = mlx4_en_poll_tx_cq;
 		cq->timer.data = (unsigned long) cq;
@@ -155,6 +168,15 @@ void mlx4_en_deactivate_cq(struct mlx4_e
 {
 	struct mlx4_en_dev *mdev = priv->mdev;
 
+#if 0 // XXX def DEV_NETMAP
+	struct netmap_adapter *na = NA(priv->dev);
+
+	if (cq->is_tx && na && (priv->dev->if_capenable & IFCAP_NETMAP) && cq->ring < na->num_tx_rings) {
+		RD(5, "deactivate napi on txq %d", cq->ring);
+		napi_disable(&cq->napi);
+		netif_napi_del(&cq->napi);
+	} else
+#endif /* !DEV_NETMAP */
 	if (cq->is_tx)
 		del_timer(&cq->timer);
 	else {
--- mellanox/mlx4/en_netdev.c	2012-09-11 20:50:55.982624673 -0700
+++ ./mellanox/mlx4/en_netdev.c	2012-09-23 17:46:55.489660556 -0700
@@ -48,6 +48,39 @@
 #include "mlx4_en.h"
 #include "en_port.h"
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+/*
+ * This driver is split in multiple small files.
+ * The main device descriptor has type struct mlx4_en_priv *priv;
+ * and we attach to the device in mlx4_en_init_netdev()
+ * (do port numbers start from 1 ?)
+ *
+ * The reconfig routine is in mlx4_en_start_port() (also here)
+ * which is called on a mlx4_en_restart() (watchdog), open and set-mtu.
+ *
+ *	priv->num_frags				??
+ *	DS_SIZE					??
+ *		apparently each rx desc is followed by frag.descriptors
+ *		and the rx desc is rounded up to a power of 2.
+ *
+ *   Receive code is in en_rx.c
+ *	priv->rx_ring_num			number of rx rings
+ *	rxr = prov->rx_ring[ring_ind]		rx ring descriptor
+ *	rxr->size				number of slots
+ *	rxr->prod				producer
+ *	   probably written into a mmio reg at *rxr->wqres.db.db
+ *	   trimmed to 16 bits.
+ *
+ *	Rx init routine:
+ *		mlx4_en_activate_rx_rings()
+ *		  mlx4_en_init_rx_desc()
+ *   Transmit code is in en_tx.c
+ */
+
+#define NETMAP_MLX4_MAIN
+#include <mlx4_netmap_linux.h>        /* extern stuff */
+#endif /* CONFIG_NETMAP */
+
 int mlx4_en_setup_tc(struct net_device *dev, u8 up)
 {
 	if (up != MLX4_EN_NUM_UP)
@@ -1042,6 +1075,9 @@ int mlx4_en_start_port(struct net_device
 		/* Set initial ownership of all Tx TXBBs to SW (1) */
 		for (j = 0; j < tx_ring->buf_size; j += STAMP_STRIDE)
 			*((u32 *) (tx_ring->buf + j)) = 0xffffffff;
+#ifdef DEV_NETMAP
+		mlx4_netmap_tx_config(priv, i);
+#endif /* DEV_NETMAP */
 		++tx_index;
 	}
 
@@ -1639,6 +1675,9 @@ int mlx4_en_init_netdev(struct mlx4_en_d
 	en_warn(priv, "Using %d RX rings\n", prof->rx_ring_num);
 
 	queue_delayed_work(mdev->workqueue, &priv->stats_task, STATS_DELAY);
+#ifdef DEV_NETMAP
+	mlx4_netmap_attach(priv);
+#endif /* DEV_NETMAP */
 	return 0;
 
 out:
--- mellanox/mlx4/en_rx.c	2012-09-11 20:50:55.982624673 -0700
+++ ./mellanox/mlx4/en_rx.c	2012-09-23 17:46:55.489660556 -0700
@@ -41,6 +41,9 @@
 
 #include "mlx4_en.h"
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#include <mlx4_netmap_linux.h>
+#endif /* !DEV_NETMAP */
 
 static int mlx4_en_alloc_frag(struct mlx4_en_priv *priv,
 			      struct mlx4_en_rx_desc *rx_desc,
@@ -365,6 +368,9 @@ int mlx4_en_activate_rx_rings(struct mlx
 		ring = &priv->rx_ring[ring_ind];
 
 		ring->size_mask = ring->actual_size - 1;
+#ifdef DEV_NETMAP
+		mlx4_netmap_rx_config(priv, ring_ind);
+#endif /* DEV_NETMAP */
 		mlx4_en_update_rx_prod_db(ring);
 	}
 
--- mellanox/mlx4/en_tx.c	2012-09-11 20:50:55.982624673 -0700
+++ ./mellanox/mlx4/en_tx.c	2012-09-25 15:14:26.126089836 -0700
@@ -55,6 +55,10 @@ MODULE_PARM_DESC(inline_thold, "threshol
 
 static u32 hashrnd __read_mostly;
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#include <mlx4_netmap_linux.h>        /* extern stuff */
+#endif /* CONFIG_NETMAP */
+
 int mlx4_en_create_tx_ring(struct mlx4_en_priv *priv,
 			   struct mlx4_en_tx_ring *ring, u32 size,
 			   u16 stride)
@@ -336,6 +340,15 @@ static void mlx4_en_process_tx_cq(struct
 	if (!priv->port_up)
 		return;
 
+#ifdef DEV_NETMAP
+{ static int cnt = 0;
+	RD(1, "XXXXXX-------XXXXXXXXXXX-------- tx-irq %d count %d", cq->ring, cnt);
+	if (netmap_tx_irq(cq->dev, cq->ring)) {
+		RD(5, "wakeup queue %d", cq->ring);
+		return;
+	}
+}
+#endif /* DEV_NETMAP */
 	index = cons_index & size_mask;
 	cqe = &buf[(index << factor) + factor];
 	ring_index = ring->cons & size_mask;
@@ -409,6 +422,9 @@ void mlx4_en_poll_tx_cq(unsigned long da
 	struct mlx4_en_tx_ring *ring = &priv->tx_ring[cq->ring];
 	u32 inflight;
 
+{static uint32_t ctr;
+	RD(1, "XXXXXX-------XXXXXXXXXXX-------- poll_tx_cq %d count %d", cq->ring, ctr++);
+}
 	INC_PERF_COUNTER(priv->pstats.tx_poll);
 
 	if (!spin_trylock_irq(&ring->comp_lock)) {
@@ -714,6 +730,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff
 	index = ring->prod & ring->size_mask;
 	bf_index = ring->prod;
 
+ND(5, "sending packet ring %d size %d", tx_ind, skb->len);
 	/* See if we have enough space for whole descriptor TXBB for setting
 	 * SW ownership on next descriptor; if not, use a bounce buffer. */
 	if (likely(index + nr_txbb <= ring->size))
@@ -799,6 +816,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff
 	data += skb_shinfo(skb)->nr_frags + tx_info->linear - 1;
 
 	if (!is_inline(skb, &fragptr)) {
+ND(5, "ring %d packet not inline, size %d frags %d", tx_ind, skb_headlen(skb), skb_shinfo(skb)->nr_frags);
 		/* Map fragments */
 		for (i = skb_shinfo(skb)->nr_frags - 1; i >= 0; i--) {
 			frag = &skb_shinfo(skb)->frags[i];
@@ -823,6 +841,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff
 		}
 		tx_info->inl = 0;
 	} else {
+ND(5, "ring %d packet inline, size %d frags %d", tx_ind, skb_headlen(skb), skb_shinfo(skb)->nr_frags);
 		build_inline_wqe(tx_desc, skb, real_size, &vlan_tag, tx_ind, fragptr);
 		tx_info->inl = 1;
 	}
@@ -849,6 +868,7 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff
 
 		mlx4_bf_copy(ring->bf.reg + ring->bf.offset, (unsigned long *) ctrl,
 		     desc_size);
+ND(5, "after mlx4_bf_copy, desc_size %d", desc_size);
 
 		wmb();
 
@@ -859,8 +879,10 @@ netdev_tx_t mlx4_en_xmit(struct sk_buff
 		wmb();
 		tx_desc->ctrl.owner_opcode = op_own;
 		wmb();
+RD(5, "ringing doorbell at %d", ring->prod); // XXX DEV_NETMAP
 		iowrite32be(ring->doorbell_qpn, ring->bf.uar->map + MLX4_SEND_DOORBELL);
 	}
+	ND(3, "dumped desc %d ring %d", ring->prod + mlx4_tx_desc_dump(tx_desc), tx_ind);
 
 	/* Poll CQ here */
 	mlx4_en_xmit_poll(priv, tx_ind);
